{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación binaria\n",
    "Se implementará un modelo de clasificación binaria para un datasets con clases altamente desbalanceadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descargar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  1 65.9M    1 1033k    0     0   902k      0  0:01:14  0:00:01  0:01:13  921k\n",
      "  3 65.9M    3 2494k    0     0  1169k      0  0:00:57  0:00:02  0:00:55 1182k\n",
      "  5 65.9M    5 3950k    0     0  1240k      0  0:00:54  0:00:03  0:00:51 1249k\n",
      "  7 65.9M    7 4958k    0     0  1193k      0  0:00:56  0:00:04  0:00:52 1200k\n",
      "  9 65.9M    9 6606k    0     0  1286k      0  0:00:52  0:00:05  0:00:47 1320k\n",
      " 12 65.9M   12 8622k    0     0  1407k      0  0:00:47  0:00:06  0:00:41 1523k\n",
      " 14 65.9M   14 9902k    0     0  1389k      0  0:00:48  0:00:07  0:00:41 1483k\n",
      " 16 65.9M   16 10.6M    0     0  1342k      0  0:00:50  0:00:08  0:00:42 1408k\n",
      " 18 65.9M   18 12.3M    0     0  1382k      0  0:00:48  0:00:09  0:00:39 1540k\n",
      " 21 65.9M   21 14.4M    0     0  1457k      0  0:00:46  0:00:10  0:00:36 1633k\n",
      " 25 65.9M   25 16.7M    0     0  1542k      0  0:00:43  0:00:11  0:00:32 1708k\n",
      " 27 65.9M   27 18.0M    0     0  1523k      0  0:00:44  0:00:12  0:00:32 1714k\n",
      " 29 65.9M   29 19.3M    0     0  1508k      0  0:00:44  0:00:13  0:00:31 1779k\n",
      " 32 65.9M   32 21.1M    0     0  1532k      0  0:00:44  0:00:14  0:00:30 1805k\n",
      " 35 65.9M   35 23.2M    0     0  1575k      0  0:00:42  0:00:15  0:00:27 1814k\n",
      " 38 65.9M   38 25.6M    0     0  1626k      0  0:00:41  0:00:16  0:00:25 1811k\n",
      " 41 65.9M   41 27.2M    0     0  1631k      0  0:00:41  0:00:17  0:00:24 1892k\n",
      " 43 65.9M   43 28.7M    0     0  1622k      0  0:00:41  0:00:18  0:00:23 1920k\n",
      " 46 65.9M   46 30.4M    0     0  1632k      0  0:00:41  0:00:19  0:00:22 1917k\n",
      " 50 65.9M   50 33.2M    0     0  1688k      0  0:00:40  0:00:20  0:00:20 2028k\n",
      " 53 65.9M   53 35.5M    0     0  1548k      0  0:00:43  0:00:23  0:00:20 1378k\n",
      " 57 65.9M   57 37.9M    0     0  1598k      0  0:00:42  0:00:24  0:00:18 1519k\n",
      " 61 65.9M   61 40.4M    0     0  1648k      0  0:00:40  0:00:25  0:00:15 1718k\n",
      " 65 65.9M   65 43.3M    0     0  1696k      0  0:00:39  0:00:26  0:00:13 1872k\n",
      " 69 65.9M   69 45.8M    0     0  1728k      0  0:00:39  0:00:27  0:00:12 1843k\n",
      " 72 65.9M   72 47.9M    0     0  1744k      0  0:00:38  0:00:28  0:00:10 2742k\n",
      " 75 65.9M   75 49.6M    0     0  1746k      0  0:00:38  0:00:29  0:00:09 2491k\n",
      " 77 65.9M   77 51.2M    0     0  1740k      0  0:00:38  0:00:30  0:00:08 2201k\n",
      " 79 65.9M   79 52.5M    0     0  1725k      0  0:00:39  0:00:31  0:00:08 1876k\n",
      " 81 65.9M   81 54.0M    0     0  1721k      0  0:00:39  0:00:32  0:00:07 1681k\n",
      " 85 65.9M   85 56.4M    0     0  1745k      0  0:00:38  0:00:33  0:00:05 1752k\n",
      " 88 65.9M   88 58.3M    0     0  1752k      0  0:00:38  0:00:34  0:00:04 1783k\n",
      " 92 65.9M   92 60.6M    0     0  1768k      0  0:00:38  0:00:35  0:00:03 1938k\n",
      " 95 65.9M   95 62.8M    0     0  1781k      0  0:00:37  0:00:36  0:00:01 2129k\n",
      " 98 65.9M   98 64.9M    0     0  1790k      0  0:00:37  0:00:37 --:--:-- 2233k\n",
      "100 65.9M  100 65.9M    0     0  1791k      0  0:00:37  0:00:37 --:--:-- 2122k\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://storage.googleapis.com/naylalex-deep-learning/Kaggle-Credit-Card-Fraud-Detection.zip\n",
    "!unzip -d datasets/credit-card-fraud-detection/ Kaggle-Credit-Card-Fraud-Detection.zip\n",
    "!rm Kaggle-Credit-Card-Fraud-Detection.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizar los datos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
      "features.shape: (284807, 30)\n",
      "targets.shape: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/\n",
    "fname = \"./datasets/credit-card-fraud-detection/creditcard.csv\"\n",
    "\n",
    "all_features = []\n",
    "all_targets = []\n",
    "with open(fname) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(\"HEADER:\", line.strip())\n",
    "            continue  # Skip header\n",
    "        fields = line.strip().split(\",\")\n",
    "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
    "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        if i == 1:\n",
    "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
    "\n",
    "features = np.array(all_features, dtype=\"float32\")\n",
    "targets = np.array(all_targets, dtype=\"uint8\")\n",
    "print(\"features.shape:\", features.shape)\n",
    "print(\"targets.shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar un dataset de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 227846\n",
      "Number of validation samples: 56961\n"
     ]
    }
   ],
   "source": [
    "num_val_samples = int(len(features) * 0.2)\n",
    "train_features = features[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_features = features[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]\n",
    "\n",
    "print(\"Number of training samples:\", len(train_features))\n",
    "print(\"Number of validation samples:\", len(val_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizar el desbalance de clases en los targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 417 (0.18% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(train_targets[:, 0])\n",
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizar los datos empleando estadísticas del training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar un modelo de clasificación binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               7936      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139777 (546.00 KB)\n",
      "Trainable params: 139777 (546.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            256, activation=\"relu\", input_shape=(train_features.shape[-1],)\n",
    "        ),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar el modelo con el argumento class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "112/112 - 7s - loss: 1.9409e-07 - fn: 0.0000e+00 - fp: 2757.0000 - tn: 224672.0000 - tp: 417.0000 - precision: 0.1314 - recall: 1.0000 - val_loss: 0.0114 - val_fn: 9.0000 - val_fp: 205.0000 - val_tn: 56681.0000 - val_tp: 66.0000 - val_precision: 0.2435 - val_recall: 0.8800 - 7s/epoch - 60ms/step\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marciano\\.conda\\envs\\class\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 - 4s - loss: 1.0067e-07 - fn: 0.0000e+00 - fp: 1191.0000 - tn: 226238.0000 - tp: 417.0000 - precision: 0.2593 - recall: 1.0000 - val_loss: 0.0071 - val_fn: 14.0000 - val_fp: 89.0000 - val_tn: 56797.0000 - val_tp: 61.0000 - val_precision: 0.4067 - val_recall: 0.8133 - 4s/epoch - 38ms/step\n",
      "Epoch 3/30\n",
      "112/112 - 4s - loss: 1.2996e-07 - fn: 1.0000 - fp: 1274.0000 - tn: 226155.0000 - tp: 416.0000 - precision: 0.2462 - recall: 0.9976 - val_loss: 0.0077 - val_fn: 14.0000 - val_fp: 83.0000 - val_tn: 56803.0000 - val_tp: 61.0000 - val_precision: 0.4236 - val_recall: 0.8133 - 4s/epoch - 39ms/step\n",
      "Epoch 4/30\n",
      "112/112 - 4s - loss: 1.1192e-07 - fn: 0.0000e+00 - fp: 1118.0000 - tn: 226311.0000 - tp: 417.0000 - precision: 0.2717 - recall: 1.0000 - val_loss: 0.0415 - val_fn: 10.0000 - val_fp: 432.0000 - val_tn: 56454.0000 - val_tp: 65.0000 - val_precision: 0.1308 - val_recall: 0.8667 - 4s/epoch - 37ms/step\n",
      "Epoch 5/30\n",
      "112/112 - 6s - loss: 2.3498e-07 - fn: 1.0000 - fp: 2139.0000 - tn: 225290.0000 - tp: 416.0000 - precision: 0.1628 - recall: 0.9976 - val_loss: 0.0164 - val_fn: 11.0000 - val_fp: 283.0000 - val_tn: 56603.0000 - val_tp: 64.0000 - val_precision: 0.1844 - val_recall: 0.8533 - 6s/epoch - 49ms/step\n",
      "Epoch 6/30\n",
      "112/112 - 4s - loss: 3.5386e-07 - fn: 2.0000 - fp: 2634.0000 - tn: 224795.0000 - tp: 415.0000 - precision: 0.1361 - recall: 0.9952 - val_loss: 0.0242 - val_fn: 8.0000 - val_fp: 353.0000 - val_tn: 56533.0000 - val_tp: 67.0000 - val_precision: 0.1595 - val_recall: 0.8933 - 4s/epoch - 35ms/step\n",
      "Epoch 7/30\n",
      "112/112 - 4s - loss: 5.0035e-07 - fn: 3.0000 - fp: 2128.0000 - tn: 225301.0000 - tp: 414.0000 - precision: 0.1629 - recall: 0.9928 - val_loss: 0.0397 - val_fn: 9.0000 - val_fp: 432.0000 - val_tn: 56454.0000 - val_tp: 66.0000 - val_precision: 0.1325 - val_recall: 0.8800 - 4s/epoch - 36ms/step\n",
      "Epoch 8/30\n",
      "112/112 - 6s - loss: 1.8882e-07 - fn: 2.0000 - fp: 1922.0000 - tn: 225507.0000 - tp: 415.0000 - precision: 0.1776 - recall: 0.9952 - val_loss: 0.0228 - val_fn: 9.0000 - val_fp: 442.0000 - val_tn: 56444.0000 - val_tp: 66.0000 - val_precision: 0.1299 - val_recall: 0.8800 - 6s/epoch - 51ms/step\n",
      "Epoch 9/30\n",
      "112/112 - 5s - loss: 2.2043e-07 - fn: 2.0000 - fp: 2769.0000 - tn: 224660.0000 - tp: 415.0000 - precision: 0.1303 - recall: 0.9952 - val_loss: 0.0274 - val_fn: 7.0000 - val_fp: 637.0000 - val_tn: 56249.0000 - val_tp: 68.0000 - val_precision: 0.0965 - val_recall: 0.9067 - 5s/epoch - 47ms/step\n",
      "Epoch 10/30\n",
      "112/112 - 5s - loss: 7.1895e-07 - fn: 2.0000 - fp: 2591.0000 - tn: 224838.0000 - tp: 415.0000 - precision: 0.1381 - recall: 0.9952 - val_loss: 0.0374 - val_fn: 9.0000 - val_fp: 867.0000 - val_tn: 56019.0000 - val_tp: 66.0000 - val_precision: 0.0707 - val_recall: 0.8800 - 5s/epoch - 44ms/step\n",
      "Epoch 11/30\n",
      "112/112 - 5s - loss: 1.8627e-06 - fn: 14.0000 - fp: 4508.0000 - tn: 222921.0000 - tp: 403.0000 - precision: 0.0821 - recall: 0.9664 - val_loss: 0.0488 - val_fn: 14.0000 - val_fp: 125.0000 - val_tn: 56761.0000 - val_tp: 61.0000 - val_precision: 0.3280 - val_recall: 0.8133 - 5s/epoch - 43ms/step\n",
      "Epoch 12/30\n",
      "112/112 - 6s - loss: 1.6303e-06 - fn: 10.0000 - fp: 4952.0000 - tn: 222477.0000 - tp: 407.0000 - precision: 0.0759 - recall: 0.9760 - val_loss: 0.0355 - val_fn: 8.0000 - val_fp: 319.0000 - val_tn: 56567.0000 - val_tp: 67.0000 - val_precision: 0.1736 - val_recall: 0.8933 - 6s/epoch - 57ms/step\n",
      "Epoch 13/30\n",
      "112/112 - 5s - loss: 5.7891e-07 - fn: 6.0000 - fp: 3937.0000 - tn: 223492.0000 - tp: 411.0000 - precision: 0.0945 - recall: 0.9856 - val_loss: 0.0570 - val_fn: 9.0000 - val_fp: 746.0000 - val_tn: 56140.0000 - val_tp: 66.0000 - val_precision: 0.0813 - val_recall: 0.8800 - 5s/epoch - 44ms/step\n",
      "Epoch 14/30\n",
      "112/112 - 5s - loss: 2.9742e-07 - fn: 2.0000 - fp: 2498.0000 - tn: 224931.0000 - tp: 415.0000 - precision: 0.1425 - recall: 0.9952 - val_loss: 0.0163 - val_fn: 9.0000 - val_fp: 302.0000 - val_tn: 56584.0000 - val_tp: 66.0000 - val_precision: 0.1793 - val_recall: 0.8800 - 5s/epoch - 42ms/step\n",
      "Epoch 15/30\n",
      "112/112 - 5s - loss: 2.1093e-07 - fn: 2.0000 - fp: 2198.0000 - tn: 225231.0000 - tp: 415.0000 - precision: 0.1588 - recall: 0.9952 - val_loss: 0.0072 - val_fn: 11.0000 - val_fp: 79.0000 - val_tn: 56807.0000 - val_tp: 64.0000 - val_precision: 0.4476 - val_recall: 0.8533 - 5s/epoch - 46ms/step\n",
      "Epoch 16/30\n",
      "112/112 - 5s - loss: 3.7702e-07 - fn: 1.0000 - fp: 1918.0000 - tn: 225511.0000 - tp: 416.0000 - precision: 0.1782 - recall: 0.9976 - val_loss: 0.0171 - val_fn: 9.0000 - val_fp: 205.0000 - val_tn: 56681.0000 - val_tp: 66.0000 - val_precision: 0.2435 - val_recall: 0.8800 - 5s/epoch - 42ms/step\n",
      "Epoch 17/30\n",
      "112/112 - 5s - loss: 1.7106e-07 - fn: 1.0000 - fp: 1243.0000 - tn: 226186.0000 - tp: 416.0000 - precision: 0.2508 - recall: 0.9976 - val_loss: 0.0223 - val_fn: 11.0000 - val_fp: 344.0000 - val_tn: 56542.0000 - val_tp: 64.0000 - val_precision: 0.1569 - val_recall: 0.8533 - 5s/epoch - 43ms/step\n",
      "Epoch 18/30\n",
      "112/112 - 5s - loss: 6.3227e-07 - fn: 4.0000 - fp: 2236.0000 - tn: 225193.0000 - tp: 413.0000 - precision: 0.1559 - recall: 0.9904 - val_loss: 0.0540 - val_fn: 10.0000 - val_fp: 566.0000 - val_tn: 56320.0000 - val_tp: 65.0000 - val_precision: 0.1030 - val_recall: 0.8667 - 5s/epoch - 47ms/step\n",
      "Epoch 19/30\n",
      "112/112 - 6s - loss: 3.9628e-07 - fn: 5.0000 - fp: 3219.0000 - tn: 224210.0000 - tp: 412.0000 - precision: 0.1135 - recall: 0.9880 - val_loss: 0.0197 - val_fn: 10.0000 - val_fp: 251.0000 - val_tn: 56635.0000 - val_tp: 65.0000 - val_precision: 0.2057 - val_recall: 0.8667 - 6s/epoch - 49ms/step\n",
      "Epoch 20/30\n",
      "112/112 - 6s - loss: 2.4308e-07 - fn: 1.0000 - fp: 1714.0000 - tn: 225715.0000 - tp: 416.0000 - precision: 0.1953 - recall: 0.9976 - val_loss: 0.0147 - val_fn: 10.0000 - val_fp: 201.0000 - val_tn: 56685.0000 - val_tp: 65.0000 - val_precision: 0.2444 - val_recall: 0.8667 - 6s/epoch - 52ms/step\n",
      "Epoch 21/30\n",
      "112/112 - 6s - loss: 3.0536e-07 - fn: 4.0000 - fp: 2937.0000 - tn: 224492.0000 - tp: 413.0000 - precision: 0.1233 - recall: 0.9904 - val_loss: 0.0368 - val_fn: 9.0000 - val_fp: 576.0000 - val_tn: 56310.0000 - val_tp: 66.0000 - val_precision: 0.1028 - val_recall: 0.8800 - 6s/epoch - 53ms/step\n",
      "Epoch 22/30\n",
      "112/112 - 6s - loss: 3.3907e-07 - fn: 4.0000 - fp: 3501.0000 - tn: 223928.0000 - tp: 413.0000 - precision: 0.1055 - recall: 0.9904 - val_loss: 0.0114 - val_fn: 11.0000 - val_fp: 158.0000 - val_tn: 56728.0000 - val_tp: 64.0000 - val_precision: 0.2883 - val_recall: 0.8533 - 6s/epoch - 57ms/step\n",
      "Epoch 23/30\n",
      "112/112 - 6s - loss: 2.0973e-07 - fn: 1.0000 - fp: 2489.0000 - tn: 224940.0000 - tp: 416.0000 - precision: 0.1432 - recall: 0.9976 - val_loss: 0.0207 - val_fn: 10.0000 - val_fp: 327.0000 - val_tn: 56559.0000 - val_tp: 65.0000 - val_precision: 0.1658 - val_recall: 0.8667 - 6s/epoch - 55ms/step\n",
      "Epoch 24/30\n",
      "112/112 - 8s - loss: 1.6820e-07 - fn: 2.0000 - fp: 1522.0000 - tn: 225907.0000 - tp: 415.0000 - precision: 0.2142 - recall: 0.9952 - val_loss: 0.0164 - val_fn: 8.0000 - val_fp: 271.0000 - val_tn: 56615.0000 - val_tp: 67.0000 - val_precision: 0.1982 - val_recall: 0.8933 - 8s/epoch - 70ms/step\n",
      "Epoch 25/30\n",
      "112/112 - 6s - loss: 1.0843e-07 - fn: 0.0000e+00 - fp: 1248.0000 - tn: 226181.0000 - tp: 417.0000 - precision: 0.2505 - recall: 1.0000 - val_loss: 0.0128 - val_fn: 8.0000 - val_fp: 184.0000 - val_tn: 56702.0000 - val_tp: 67.0000 - val_precision: 0.2669 - val_recall: 0.8933 - 6s/epoch - 52ms/step\n",
      "Epoch 26/30\n",
      "112/112 - 7s - loss: 1.7065e-07 - fn: 3.0000 - fp: 1623.0000 - tn: 225806.0000 - tp: 414.0000 - precision: 0.2032 - recall: 0.9928 - val_loss: 0.0509 - val_fn: 7.0000 - val_fp: 744.0000 - val_tn: 56142.0000 - val_tp: 68.0000 - val_precision: 0.0837 - val_recall: 0.9067 - 7s/epoch - 63ms/step\n",
      "Epoch 27/30\n",
      "112/112 - 6s - loss: 1.9660e-07 - fn: 2.0000 - fp: 2605.0000 - tn: 224824.0000 - tp: 415.0000 - precision: 0.1374 - recall: 0.9952 - val_loss: 0.0089 - val_fn: 10.0000 - val_fp: 147.0000 - val_tn: 56739.0000 - val_tp: 65.0000 - val_precision: 0.3066 - val_recall: 0.8667 - 6s/epoch - 55ms/step\n",
      "Epoch 28/30\n",
      "112/112 - 6s - loss: 1.3391e-07 - fn: 1.0000 - fp: 1490.0000 - tn: 225939.0000 - tp: 416.0000 - precision: 0.2183 - recall: 0.9976 - val_loss: 0.0104 - val_fn: 10.0000 - val_fp: 163.0000 - val_tn: 56723.0000 - val_tp: 65.0000 - val_precision: 0.2851 - val_recall: 0.8667 - 6s/epoch - 57ms/step\n",
      "Epoch 29/30\n",
      "112/112 - 6s - loss: 1.5634e-07 - fn: 1.0000 - fp: 2023.0000 - tn: 225406.0000 - tp: 416.0000 - precision: 0.1706 - recall: 0.9976 - val_loss: 0.0106 - val_fn: 10.0000 - val_fp: 194.0000 - val_tn: 56692.0000 - val_tp: 65.0000 - val_precision: 0.2510 - val_recall: 0.8667 - 6s/epoch - 56ms/step\n",
      "Epoch 30/30\n",
      "112/112 - 6s - loss: 1.1554e-07 - fn: 0.0000e+00 - fp: 1243.0000 - tn: 226186.0000 - tp: 417.0000 - precision: 0.2512 - recall: 1.0000 - val_loss: 0.0144 - val_fn: 10.0000 - val_fp: 244.0000 - val_tn: 56642.0000 - val_tp: 65.0000 - val_precision: 0.2104 - val_recall: 0.8667 - 6s/epoch - 53ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22c3faa46d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"logs/fraud_model_at_epoch_{epoch}.h5\")]\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=2048,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(val_features, val_targets),\n",
    "    class_weight=class_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "* Número de transacciones de validación.\n",
    "* Número de casos identificados correctamente como fraudulentos.\n",
    "* Número de transacciones fraudulentas faltantes.\n",
    "* Costo de etiquetar 441 transacciones legítimas.\n",
    "Recomendaciones: Colocar un peso mayor en la clase 1 para reflejar que los falsos negativos son más costosos que los falsos positivos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
